{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Advanced Lane Line Detection Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plots two images on the same row one representing the original image, the other reporesnt a modified image\n",
    "def plt2ImagesSideBySide(image1, label1, image2, label2, isgray = False):\n",
    "    #below code is inspired from https://stackoverflow.com/questions/17111525/how-to-show-multiple-images-in-one-figure\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    orig = fig.add_subplot(1,2,1)\n",
    "    \n",
    "    if(isgray == False):\n",
    "        origimgplot = plt.imshow(image1)\n",
    "    else:\n",
    "        origimgplot = plt.imshow(image1, cmap='gray')\n",
    "    \n",
    "    orig.set_title(label1)\n",
    "    modif = fig.add_subplot(1,2,2)\n",
    "    \n",
    "    if(isgray == False):\n",
    "        modifimgplot = plt.imshow(image2)\n",
    "    else:\n",
    "        modifimgplot = plt.imshow(image2, cmap='gray')\n",
    "    modif.set_title(label2)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def pltImages(images, labels, nrows = 1, ncols = 2, fig_w = 20, fig_h = 10, isgray = False):\n",
    "    #below code is inspired from https://stackoverflow.com/questions/17111525/how-to-show-multiple-images-in-one-figure\n",
    "    assert len(images) == len(labels)\n",
    "    assert len(images) <= (nrows * ncols)\n",
    "    \n",
    "    fig = plt.figure(figsize=(fig_w, fig_h))\n",
    "    \n",
    "    for index in range(len(images)):\n",
    "        plot = fig.add_subplot(nrows,ncols,index+1)\n",
    "        plot.set_title(labels[index])\n",
    "        if(isgray == False):\n",
    "            plt.imshow(images[index].squeeze())\n",
    "        else:\n",
    "            plt.imshow(images[index].squeeze(), cmap='gray')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CollectImages(folderpath, ImagePaths):\n",
    "    images = []\n",
    "    for ImagePath in ImagePaths:\n",
    "        im = mpimg.imread(folderpath + ImagePath)\n",
    "        #print('This image' , ImagePath , 'is:', type(im), 'with dimensions:', im.shape)\n",
    "        images.append((im, ImagePath.split('.')[0]))\n",
    "        \n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ProcessCalibImages(CalImages, boardSize):\n",
    "    #Create two empty arrays to store points in distorated and undistorted image domains.\n",
    "    objPts = [] # 3d points in real world space\n",
    "    ImgPts = [] # 2d points in image plane.\n",
    "    \n",
    "    #Initialize objp to an array with index 0,0,0 -> 8,5,0\n",
    "    objp = np.zeros((boardSize[0]*boardSize[1], 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:boardSize[0], 0:boardSize[1]].T.reshape(-1, 2)\n",
    "    \n",
    "    for img, label in CalImages:    \n",
    "        grayImage = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)    \n",
    "        \n",
    "        ret, corners = cv2.findChessboardCorners(grayImage, boardSize, None)\n",
    "    \n",
    "        if ret == True:\n",
    "            objPts.append(objp)\n",
    "            ImgPts.append(corners)\n",
    "        else:\n",
    "            print(\"Finding Calibration Image points failed for image\" + label)\n",
    "        \n",
    "    return objPts, ImgPts\n",
    "\n",
    "def CalculateCamMat(objPts, ImgPts, img_size):\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objPts, ImgPts, img_size,None,None)\n",
    "    return mtx, dist\n",
    "\n",
    "def UnDistortImage(img, mtx, dist):\n",
    "    return cv2.undistort(img, mtx, dist, None, mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CamCalimagesPaths = os.listdir(\"camera_cal/\")\n",
    "\n",
    "CalImages = CollectImages(\"camera_cal/\", CamCalimagesPaths)\n",
    "\n",
    "print(\"Calibration Image Examples\")\n",
    "\n",
    "plt2ImagesSideBySide(CalImages[0][0], \"Example 1\", CalImages[3][0], \"Example 2\")\n",
    "\n",
    "UndistPts, DistPts = ProcessCalibImages(CalImages, (9,6))\n",
    "\n",
    "#All images are of same size (1280 * 720 * 3) get image size from the first one.\n",
    "img_size = (CalImages[0][0].shape[1], CalImages[0][0].shape[0])\n",
    "\n",
    "CamMtx, Dist = CalculateCamMat(UndistPts, DistPts, img_size)\n",
    "\n",
    "Example1 = UnDistortImage(CalImages[0][0], CamMtx, Dist)\n",
    "Example2 = UnDistortImage(CalImages[3][0], CamMtx, Dist)\n",
    "\n",
    "plt2ImagesSideBySide(Example1, \"Example 1 UnDistorted\", Example2, \"Example 2 UnDistorted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test PipeLine on Test Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color Space conversion helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def LABColorFormat(img):\n",
    "    # LAB is chosen for it's robustness aganist changing lighting conditions.\n",
    "    # This is due to Lightness being a seperate parameter 'L'.\n",
    "    # LAB is also useful because the maximum B values represent pure yellow so yellow lane lines would be easier to detect.\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2LAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color and Spatial filtering functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_lanes_by_color(image):\n",
    "    #convert to LAB color space\n",
    "    LAB_format = LABColorFormat(image)\n",
    "    \n",
    "    # define range of white color in LAB color space\n",
    "    lower_white = np.array([210,126,126])\n",
    "    upper_white = np.array([255,137,137])\n",
    "\n",
    "    # Threshold the LAB image to get only white colors\n",
    "    white_mask = cv2.inRange(LAB_format, lower_white, upper_white)\n",
    "\n",
    "    # define range of yellow color in LAB color space\n",
    "    lower_yellow = np.array([0,0,158])\n",
    "    upper_yellow = np.array([255,255,255])\n",
    "\n",
    "    # Threshold the LAB image to get only blue colors\n",
    "    yellow_mask = cv2.inRange(LAB_format, lower_yellow, upper_yellow)\n",
    "\n",
    "    #Bitwise OR the white and yellow masks\n",
    "    merged_mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "\n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv2.bitwise_and(image,image, mask= merged_mask)\n",
    "    return res\n",
    "\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)\n",
    "    \n",
    "    ignore_mask_color = (255,) * img.shape[2]\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV Wrapper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Sobel Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SobelThresholding(gray_img, sobel_kernel=3, Sobel_Trheshold=(0,255,0,90)):\n",
    "    #Convert from deg to rad\n",
    "    low_ang_threshold  = (Sobel_Trheshold[2] / 180 * np.pi)\n",
    "    high_ang_threshold = (Sobel_Trheshold[3] / 180 * np.pi)\n",
    "    \n",
    "    #Apply sobel gradient calculation on input\n",
    "    sobel_x = cv2.Sobel(gray_img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(gray_img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    #Calculate magnitude of derivative sqrt(x'^2 + y'^2).\n",
    "    sobel_mag  = np.sqrt(sobel_x ** 2 + sobel_y ** 2)\n",
    "    #Scale sobel gradient magnitude to 0->255.\n",
    "    scld_sobel = np.uint8( 255 * sobel_mag / np.max(sobel_mag) )\n",
    "    \n",
    "    #Calculate direction of magnitude of the sobel gradient.\n",
    "    absgraddir = np.arctan2(np.absolute(sobel_y), np.absolute(sobel_x))\n",
    "    \n",
    "    #Sanity Check\n",
    "    assert absgraddir.shape == sobel_mag.shape\n",
    "    \n",
    "    #Create blank canvas to draw on.\n",
    "    binary_output =  np.zeros_like(sobel_mag)\n",
    "    \n",
    "    # Create masks to threshold the input image\n",
    "    magnitude_mask = cv2.inRange(scld_sobel, Sobel_Trheshold[0], Sobel_Trheshold[1])\n",
    "    directon_mask  = cv2.inRange(absgraddir, low_ang_threshold, high_ang_threshold)\n",
    "\n",
    "    #Bitwise OR the white and yellow masks\n",
    "    merged_mask = cv2.bitwise_or(magnitude_mask, directon_mask)\n",
    "\n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv2.bitwise_and(gray_img,gray_img, mask= merged_mask)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prespective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_h = 720\n",
    "img_w = 1280\n",
    "\n",
    "#I have tried to have a more modular approch by obtaining values using image dimensions, however non satisfactory results \n",
    "# was the output, so i had to be more aggressive by assigning constant values.\n",
    "'''bottom_left  = [img_w * 0.17, img_h]\n",
    "top_left     = [img_w * 0.45, img_h * 0.65]\n",
    "top_right    = [img_w * 0.56, img_h * 0.65]\n",
    "bottom_right = [img_w * 0.86, img_h]'''\n",
    "bottom_left  = [217, 720]\n",
    "top_left     = [570, 468]\n",
    "top_right    = [716, 468]\n",
    "bottom_right = [1100, 720]\n",
    "#order bottom_left, top_left, top_right, bottom_right\n",
    "src = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.float32)\n",
    "\n",
    "'''bottom_left  = [img_w * 0.25, img_h]\n",
    "top_left     = [img_w * 0.25, 0]\n",
    "top_right    = [img_w * 0.72, 0]\n",
    "bottom_right = [img_w * 0.72, img_h]'''\n",
    "\n",
    "bottom_left  = [320, 720]\n",
    "top_left     = [320, 0]\n",
    "top_right    = [921, 0]\n",
    "bottom_right = [921, 720]\n",
    "#order bottom_left, top_left, top_right, bottom_right\n",
    "dst = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.float32)\n",
    "\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "MInv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "def WarpImage(img):\n",
    "    img_h = img.shape[0]\n",
    "    img_w = img.shape[1]\n",
    "    \n",
    "    warped = cv2.warpPerspective(img, M, (img_w, img_h))\n",
    "    \n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Extract_feature_from_image(image, label, blurKS, SobelKS, SobelThrhld, verticies, pltImage = False):\n",
    "    colorfilteredImage = filter_lanes_by_color(image)\n",
    "    \n",
    "    grayScalImage = grayscale(colorfilteredImage)\n",
    "    \n",
    "    blurredImage  = gaussian_blur(grayScalImage, blurKS)\n",
    "    \n",
    "    gradientImage = SobelThresholding(blurredImage, sobel_kernel=SobelKS, Sobel_Trheshold=SobelThrhld)\n",
    "    \n",
    "    gradientImage = gradientImage.reshape(image.shape[0], image.shape[1], 1)\n",
    "    \n",
    "    spatialFilteredImage = region_of_interest(gradientImage, verticies)\n",
    "    \n",
    "    WarpedImage = WarpImage(spatialFilteredImage)\n",
    "    \n",
    "    if pltImage == True:\n",
    "        plt2ImagesSideBySide(spatialFilteredImage, label, WarpedImage, 'Processed', True)\n",
    "    \n",
    "    return WarpedImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function process an image to genretae a warped, thresholded and \n",
    "#undistorted image.\n",
    "def UnDistortImages(im):\n",
    "    UndistortedImg = UnDistortImage(im, CamMtx, Dist)\n",
    "    return UndistortedImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code in this function inspired from https://stackoverflow.com/questions/30242898/vertical-line-in-histogram-with-pyplot \n",
    "def visualizeHistogram(image, label, hist, Leftpeak, Rightpeak):\n",
    "    fig = plt.figure(figsize=(17, 4))\n",
    "    orig = fig.add_subplot(1,2,1)\n",
    "    orig.set_title(label)\n",
    "    orig.axvline(x=Leftpeak, color='r', linestyle='dashed', linewidth=2)\n",
    "    orig.axvline(x=Rightpeak, color='r', linestyle='dashed', linewidth=2)\n",
    "    orig.plot(histogram)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def slidingWindowBlindSearch(image, undist, label, hist, winCnt, margin, thrshld, visualize = False):\n",
    "    if visualize == True:\n",
    "        out_img = np.dstack((image, image, image))*255\n",
    "\n",
    "    img_h = image.shape[0]\n",
    "    img_w = image.shape[1]\n",
    "\n",
    "    #divide the histogram to two halfs each one contains one lane (right/left)\n",
    "    midpoint    = np.int(hist.shape[0]/2)\n",
    "    #leftx_base represent the center of the left lane peak in histogram\n",
    "    leftx_base  = np.argmax(histogram[:midpoint])\n",
    "    #rightx_base represent the center of the right lane peak in histogram\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    #visualizeHistogram(image, label, hist, leftx_base, rightx_base)\n",
    "\n",
    "    # Calculate height of each window\n",
    "    window_height = np.int(img_h/winCnt)\n",
    "\n",
    "    #Identify postively thresholded pixels in image\n",
    "    actvpxl  = image.nonzero()\n",
    "    #nonzero return a tupple of arrays representing the x and y cordintes of the non zero element in the matrix\n",
    "    Xactvpxl = actvpxl[1]\n",
    "    Yactvpxl = actvpxl[0]\n",
    "   \n",
    "    leftx  = []\n",
    "    lefty  = []\n",
    "    rightx = []\n",
    "    righty = []\n",
    "\n",
    "    win_top    = img_h - window_height\n",
    "    win_bottom = img_h\n",
    "\n",
    "    for window in range(winCnt):\n",
    "        #Calculate window position in the image\n",
    "        lwin_left  = leftx_base - margin\n",
    "        lwin_right = leftx_base + margin\n",
    "\n",
    "        rwin_left  = rightx_base - margin\n",
    "        rwin_right = rightx_base + margin\n",
    "\n",
    "        if visualize == True:\n",
    "            #draw two rectangles to visualize\n",
    "            cv2.rectangle(out_img,(lwin_left, win_bottom),(lwin_right,win_top), (0,255,0), 2)\n",
    "            cv2.rectangle(out_img,(rwin_left, win_bottom),(rwin_right,win_top), (0,255,0), 2)\n",
    "\n",
    "        #below five lines are inspired from https://stackoverflow.com/questions/5642457/how-does-python-numpy-where-work\n",
    "        #using lwin_left < Xactvpxl < lwin_right failed because numpy doesnt support comparing two binary arrays\n",
    "        lwinXactvpxl = (lwin_left < Xactvpxl) & (Xactvpxl < lwin_right)\n",
    "        rwinXactvpxl = (rwin_left < Xactvpxl) & (Xactvpxl < rwin_right)\n",
    "        winYactvpxl  = (win_top < Yactvpxl)   & (Yactvpxl < win_bottom)\n",
    "\n",
    "        lwinactvpxlidx = np.where(lwinXactvpxl & winYactvpxl)[0]\n",
    "        rwinactvpxlidx = np.where(rwinXactvpxl & winYactvpxl)[0]\n",
    "\n",
    "        lwinactvpxl = Xactvpxl[lwinactvpxlidx]\n",
    "        rwinactvpxl = Xactvpxl[rwinactvpxlidx]\n",
    "\n",
    "        leftx.append(lwinactvpxl)\n",
    "        lefty.append(Yactvpxl[lwinactvpxlidx])\n",
    "        rightx.append(rwinactvpxl)\n",
    "        righty.append(Yactvpxl[rwinactvpxlidx])\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(lwinactvpxlidx) > thrshld:\n",
    "            leftx_base = np.int(np.mean(lwinactvpxl))\n",
    "\n",
    "        if len(rwinactvpxlidx) > thrshld:\n",
    "            rightx_base = np.int(np.mean(rwinactvpxl))\n",
    "\n",
    "        win_top    -= window_height\n",
    "        win_bottom -= window_height\n",
    "\n",
    "    leftx  = np.concatenate(leftx)\n",
    "    lefty  = np.concatenate(lefty)\n",
    "    rightx = np.concatenate(rightx)\n",
    "    righty = np.concatenate(righty)\n",
    "\n",
    "    left_fit  = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    #calculate curvature\n",
    "    y_eval = np.max(lefty)\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    #convert from pixel space to real world space\n",
    "    left_fit_cr  = np.polyfit(lefty * ym_per_pix, leftx * xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty * ym_per_pix, rightx * xm_per_pix, 2)\n",
    "    \n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "\n",
    "    #Caclculate car offset from the lane center\n",
    "    leftlane   = left_fit[0]*img_h**2 + left_fit[1]*img_h + left_fit[2]\n",
    "    rightlane  = right_fit[0]*img_h**2 + right_fit[1]*img_h + right_fit[2]\n",
    "\n",
    "    lanecenter = int((leftlane + rightlane) / 2)\n",
    "\n",
    "    #camera is assumed to be in the middle of the car\n",
    "    offset = (img_w / 2) - lanecenter\n",
    "    \n",
    "    # Create an image to draw the lane on\n",
    "    warp_zero   = np.zeros_like(image).astype(np.uint8)\n",
    "    text_canvas = np.dstack((warp_zero, warp_zero, warp_zero)) \n",
    "    color_warp  = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    ploty = np.linspace(0, img_h-1, img_h)\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarplane = cv2.warpPerspective(color_warp, MInv, (img_w, img_h))\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    buffer = 'Lane Curvature is ' + str(int((left_curverad + right_curverad) / 2))\n",
    "    cv2.putText(text_canvas, buffer, (50,50), font, 1,(255,255,0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    buffer = (\"Car is off lane center by {:.3f} left of lane center\".format(offset * xm_per_pix))\n",
    "    cv2.putText(text_canvas, buffer, (50,90), font, 1,(255,255,0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarplane, 0.3, 0)\n",
    "    result = cv2.addWeighted(result, 1, text_canvas, 1, 0)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TestimagesPaths = os.listdir(\"test_images/\")\n",
    "\n",
    "TestImages = CollectImages(\"test_images/\", TestimagesPaths)\n",
    "\n",
    "for image, label in TestImages:\n",
    "    img_h = image.shape[0]\n",
    "    img_w = image.shape[1]\n",
    "\n",
    "    top_left     = [img_w * 0.45, img_h * 0.6]\n",
    "    top_right    = [img_w * 0.57, img_h * 0.6]\n",
    "    bottom_left  = [img_w * 0.1, img_h]\n",
    "    bottom_right = [img_w * 0.97, img_h]\n",
    "    verticies = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "\n",
    "    blurKernelSize  = 7\n",
    "    SobelKernelSize = 3\n",
    "    SobelThresholds = [0, 25, 40, 70]\n",
    "    \n",
    "    #Preprocess an image to generate an undistorted image.\n",
    "    UndistortedImg = UnDistortImages(image)\n",
    "    \n",
    "    #Preprocess an image to generate a warped, thresholded image.\n",
    "    processedImage = Extract_feature_from_image(UndistortedImg, label, blurKernelSize, SobelKernelSize, SobelThresholds, verticies, False)\n",
    "    \n",
    "    #Calculate histogram of the preprocessed image.\n",
    "    histogram = np.sum(processedImage[processedImage.shape[0]//2:,:], axis=0)\n",
    "    \n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 10\n",
    "    #define the size on both sides of the lane center to be searched for lane line\n",
    "    margin = 50\n",
    "    #Number of pixels to be found on one side to update the window center\n",
    "    activeThreshold = 4000\n",
    "    \n",
    "    annotatedImage = slidingWindowBlindSearch(processedImage, UndistortedImg, label, histogram, nwindows, margin, activeThreshold, True)\n",
    "    \n",
    "    images = [image, UndistortedImg, processedImage, annotatedImage]\n",
    "    labels = [label, label+' Undistorted', label+' Wraped Thresholded', label+' Annotated']\n",
    "    pltImages(images, labels, nrows = 2, ncols = 2, isgray = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slidingWindowBlindSearch_video(image, hist, winCnt, margin, thrshld, visualize = False):\n",
    "    img_h = image.shape[0]\n",
    "    img_w = image.shape[1]\n",
    "\n",
    "    #divide the histogram to two halfs each one contains one lane (right/left)\n",
    "    midpoint    = np.int(hist.shape[0]/2)\n",
    "    #leftx_base represent the center of the left lane peak in histogram\n",
    "    leftx_base  = np.argmax(histogram[:midpoint])\n",
    "    #rightx_base represent the center of the right lane peak in histogram\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Calculate height of each window\n",
    "    window_height = np.int(img_h/winCnt)\n",
    "\n",
    "    #Identify postively thresholded pixels in image\n",
    "    actvpxl  = image.nonzero()\n",
    "    #nonzero return a tupple of arrays representing the x and y cordintes of the non zero element in the matrix\n",
    "    Xactvpxl = actvpxl[1]\n",
    "    Yactvpxl = actvpxl[0]\n",
    "\n",
    "    leftx  = []\n",
    "    lefty  = []\n",
    "    rightx = []\n",
    "    righty = []\n",
    "\n",
    "    win_top    = img_h - window_height\n",
    "    win_bottom = img_h\n",
    "\n",
    "    for window in range(winCnt):\n",
    "        #Calculate window position in the image\n",
    "        lwin_left  = leftx_base - margin\n",
    "        lwin_right = leftx_base + margin\n",
    "\n",
    "        rwin_left  = rightx_base - margin\n",
    "        rwin_right = rightx_base + margin\n",
    "\n",
    "        #below five lines are inspired from https://stackoverflow.com/questions/5642457/how-does-python-numpy-where-work\n",
    "        #using lwin_left < Xactvpxl < lwin_right failed because numpy doesnt support comparing two binary arrays\n",
    "        lwinXactvpxl = (lwin_left < Xactvpxl) & (Xactvpxl < lwin_right)\n",
    "        rwinXactvpxl = (rwin_left < Xactvpxl) & (Xactvpxl < rwin_right)\n",
    "        winYactvpxl  = (win_top < Yactvpxl)   & (Yactvpxl < win_bottom)\n",
    "\n",
    "        lwinactvpxlidx = np.where(lwinXactvpxl & winYactvpxl)[0]\n",
    "        rwinactvpxlidx = np.where(rwinXactvpxl & winYactvpxl)[0]\n",
    "\n",
    "        lwinactvpxl = Xactvpxl[lwinactvpxlidx]\n",
    "        rwinactvpxl = Xactvpxl[rwinactvpxlidx]\n",
    "\n",
    "        leftx.append(lwinactvpxl)\n",
    "        lefty.append(Yactvpxl[lwinactvpxlidx])\n",
    "        rightx.append(rwinactvpxl)\n",
    "        righty.append(Yactvpxl[rwinactvpxlidx])\n",
    "\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(lwinactvpxlidx) > thrshld:\n",
    "            leftx_base = np.int(np.mean(lwinactvpxl))\n",
    "\n",
    "        if len(rwinactvpxlidx) > thrshld:\n",
    "            rightx_base = np.int(np.mean(rwinactvpxl))\n",
    "\n",
    "        win_top    -= window_height\n",
    "        win_bottom -= window_height\n",
    "\n",
    "    leftx  = np.concatenate(leftx)\n",
    "    lefty  = np.concatenate(lefty)\n",
    "    rightx = np.concatenate(rightx)\n",
    "    righty = np.concatenate(righty)\n",
    "\n",
    "    left_fit  = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    #calculate curvature\n",
    "    y_eval = np.max(lefty)\n",
    "    ym_per_pix = 30/720  # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    #convert from pixel space to real world space\n",
    "    left_fit_cr  = np.polyfit(lefty * ym_per_pix, leftx * xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty * ym_per_pix, rightx * xm_per_pix, 2)\n",
    "\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    #Caclculate car offset from the lane center\n",
    "    leftlane   = left_fit[0]*img_h**2 + left_fit[1]*img_h + left_fit[2]\n",
    "    rightlane  = right_fit[0]*img_h**2 + right_fit[1]*img_h + right_fit[2]\n",
    "\n",
    "    lanecenter = int((leftlane + rightlane) / 2)\n",
    "\n",
    "    #camera is assumed to be in the middle of the car\n",
    "    offset = ((img_w / 2) - lanecenter)  * xm_per_pix\n",
    "    \n",
    "    return (left_fit, right_fit, left_curverad, right_curverad, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drawLaneLines(image, polyCoeff, curvature, offset):\n",
    "    left_fit, right_fit = polyCoeff\n",
    "\n",
    "    out_img = np.dstack((image, image, image))*255\n",
    "\n",
    "    # Create an image to draw the lane on\n",
    "    text_canvas = np.zeros_like(image).astype(np.uint8)\n",
    "    color_warp  = np.zeros_like(image).astype(np.uint8)\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    ploty      = np.linspace(0, img_h-1, img_h)\n",
    "\n",
    "    left_fitx  = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    pts_left   = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right  = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarplane = cv2.warpPerspective(color_warp, MInv, (img_w, img_h))\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    buffer = 'Lane Curvature is ' + str(curvature)\n",
    "    cv2.putText(text_canvas, buffer, (50,50), font, 1,(255,255,0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    buffer = (\"Car is {:.3f} left of lane center\".format(offset))\n",
    "    cv2.putText(text_canvas, buffer, (50,90), font, 1,(255,255,0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(image, 1, newwarplane, 0.3, 0)\n",
    "    result = cv2.addWeighted(result, 1, text_canvas, 1, 0)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queue = []\n",
    "queue_size = 12\n",
    "\n",
    "def process_frame(image):\n",
    "    img_h = image.shape[0]\n",
    "    img_w = image.shape[1]\n",
    "    \n",
    "    top_left     = [img_w * 0.45, img_h * 0.6]\n",
    "    top_right    = [img_w * 0.57, img_h * 0.6]\n",
    "    bottom_left  = [img_w * 0.1, img_h]\n",
    "    bottom_right = [img_w * 0.97, img_h]\n",
    "    verticies = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "\n",
    "    blurKernelSize  = 7\n",
    "    SobelKernelSize = 3\n",
    "    SobelThresholds = [0, 25, 40, 70]\n",
    "    \n",
    "    #Preprocess an image to generate an undistorted image.\n",
    "    UndistortedImg = UnDistortImages(image)\n",
    "    \n",
    "    #Preprocess an image to generate a warped, thresholded image.\n",
    "    processedImage = Extract_feature_from_image(UndistortedImg, label, blurKernelSize, SobelKernelSize, SobelThresholds, verticies, False)\n",
    "    \n",
    "    #Calculate histogram of the preprocessed image.\n",
    "    histogram = np.sum(processedImage[processedImage.shape[0]//2:,:], axis=0)\n",
    "    \n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 5\n",
    "    #define the size on both sides of the lane center to be searched for lane line\n",
    "    margin = 50\n",
    "    #Number of pixels to be found on one side to update the window center\n",
    "    activeThreshold = 2000\n",
    "    \n",
    "    polyCoeff = slidingWindowBlindSearch_video(processedImage, histogram, nwindows, margin, activeThreshold)\n",
    "    \n",
    "    left_fit, right_fit, llcurv, rlcurv, offset = polyCoeff\n",
    "    \n",
    "    #Sanity check that the two lines curvature is not very far\n",
    "    rlcurv_min = rlcurv * 0.2\n",
    "    rlcurv_max = rlcurv * 2.5\n",
    "\n",
    "    if rlcurv_min < llcurv < rlcurv_max:\n",
    "        #curvature is withing acceptable range\n",
    "        curvature = int((llcurv + rlcurv) / 2)\n",
    "        \n",
    "        queue.append((polyCoeff, curvature))\n",
    "        if(len(queue) > queue_size):\n",
    "            queue.pop(0)\n",
    "\n",
    "    avgleft_fit  = []\n",
    "    avgright_fit = []\n",
    "    avgcurvature = 0\n",
    "    avgoffset    = 0\n",
    "    \n",
    "    for elm in queue:\n",
    "        polyCoeff, curvature = elm\n",
    "        left_fit, right_fit, left_curverad, right_curverad, offset = polyCoeff\n",
    "        avgleft_fit.append(left_fit)\n",
    "        avgright_fit.append(right_fit)\n",
    "        avgcurvature += curvature\n",
    "        avgoffset    += offset\n",
    "\n",
    "    avgleft_fit  = [sum(i) for i in zip(*avgleft_fit)]\n",
    "    avgleft_fit  = [i / len(queue) for i in avgleft_fit]\n",
    "    avgright_fit = [sum(i) for i in zip(*avgright_fit)]\n",
    "    avgright_fit = [i / len(queue) for i in avgright_fit]\n",
    "    avgcurvature /= len(queue)\n",
    "    avgoffset    /= len(queue)\n",
    "    \n",
    "    annotatedImage = drawLaneLines(UndistortedImg, (avgleft_fit, avgright_fit), int(avgcurvature), avgoffset)\n",
    "\n",
    "    '''images = [image, UndistortedImg, processedImage, annotatedImage]\n",
    "    labels = ['orig', ' Undistorted', ' Wraped Thresholded', ' Annotated']\n",
    "    pltImages(images, labels, nrows = 2, ncols = 2, isgray = True)'''\n",
    "    return annotatedImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "project_output = 'project_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "project_clip = clip1.fl_image(process_frame)\n",
    "%time project_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"340\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
